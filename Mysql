锁升级：行级锁 -> 表级锁(额外开销，要有死锁监测机制)
  lock:对象是事务，锁定的是数据库中的对象(表、页、行)，在事务commit或rollback时释放，存在于Lock Manager的哈希表中
  latch(mutex互斥量和rwlock读写锁):对象是线程，保护(锁定)的是内存数据结构，show engine innodb mutex查看
<!-----------------------------  
出现死锁的时候，如果只是想解锁，用show full processlist看下kill掉就好了，如果想查找到详细的问题，一个办法是用show engine innodb status来查看简略信息或者开死锁日志，后期在mysql日志里面慢慢分析。
以上这写方法我们都用过，最近在看Innodb的书的时候发现另一种实时的分析方法，能最大限度的分析死锁的原因。

MySQL 5.5 版本以后，information_schema（ski:mə） 库中新增了三个关于锁的表，亦即 innodb_trx 、innodb_locks 和 innodb_lock_waits 。
其中 innodb_trx 表记录当前运行的所有事务，innodb_locks 表记录当前出现的锁，innodb_lock_waits 表记录锁等待的对应关系。  
<!------------------------------  
debug模式:在 cmake 的时候，增加参数 cmake -DWITH_DEBUG=1   

索引:B+树:B树和ISAM(顺序罗列方法)结合，既可以像二叉平衡树所有旋，也可以删除，两层叶子结点
    辅助索引:不保存每行所有信息，explain sql时可看索引优化，
    聚集索引:组合索引 show engine innodb index 最左匹配，b未必排序，在leaf节点双向链表，(1,2)最左排序

https://linux.linuxidc.com/index.php


group_concat

用户积分清零(千万级):1、建立2个积分字段A,B。对表建立可更新视图，时间一到在视图中把字段换掉，然后在慢慢把积分清空... 
                  2、建立2个积分字段A,B。程序控制A,B哪个字段是当前的积分字段。时间一到配置中心修改这个字段指定哪一个，然后在慢慢把积分清空 
                  积分字段分奇偶， 根据日期来读取， 奇年读奇不管偶， 偶年读偶不管奇， 空闲清空旧字段
                  
 https://mp.weixin.qq.com/s/ZrrLUNRlAXVfVKvA1m0nsg（sql审核）                 

 
阿里开源Canal:基于mysql数据库binlog的增量订阅&消费
    1.canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议
    2.mysql master收到dump请求，开始推送binary log给slave(也就是canal)
    3.canal解析binary log对象(原始为byte流)
    
Explain：mysql执行计划
        https://www.cnblogs.com/wanbin/p/9565799.html


http://www.infoq.com/cn/articles/database-timestamp-02?utm_source=infoq&utm_medium=related_content_link&utm_campaign=relatedContent_articles_clk
Term Index (a,b..) -> Term Dictionary(Ada../Bob) ->Posting List([],[])
Mysql只有term dictionary这一层，是以b-tree排序的方式存储在磁盘上的。检索一个term需要若干次的random access的磁盘操作。
而Lucene在term dictionary的基础上添加了term index来加速检索，term index以树的形式缓存在内存中。
从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘的random access次数。


mysql8.0 之前的版本中加密规则是mysql_native_password,而在mysql8之后,加密规则是caching_sha2_password, 解决此问题方法有两种,一种是升级客户端驱动,一种是把mysql用户登录密码加密规则还原成mysql_native_password

<!-----------------------------------------------------------------------------------!>
Group By临时表：
    1. 如果GROUP BY 的列没有索引,产生临时表.
　　2. 如果GROUP BY时,SELECT的列不止GROUP BY列一个,并且GROUP BY的列不是主键 ,产生临时表.
　　3. 如果GROUP BY的列有索引,ORDER BY的列没索引.产生临时表.
　　4. 如果GROUP BY的列和ORDER BY的列不一样,即使都有索引也会产生临时表.
　　5. 如果GROUP BY或ORDER BY的列不是来自JOIN语句第一个表.会产生临时表.
　　6. 如果DISTINCT 和 ORDER BY的列没有索引,产生临时表.

内联表查询一般的执行过程是： 
   1、执行FROM语句 2、执行ON过滤 3、添加外部行 4、执行where条件过滤 5、执行group by分组语句 
   6、执行having 7、select列表 8、执行distinct去重复数据 9、执行order by字句 10、执行limit字句

    临时表存储

MySQL临时表分为“内存临时表”和“磁盘临时表”，其中内存临时表使用MySQL的MEMORY存储引擎，磁盘临时表使用MySQL的MyISAM存储引擎；
一般情况下，MySQL会先创建内存临时表，但内存临时表超过配置指定的值后，MySQL会将内存临时表导出到磁盘临时表；

    使用临时表的场景

1）ORDER BY子句和GROUP BY子句不同， 例如：ORDERY BY price GROUP BY name；
2）在JOIN查询中，ORDER BY或者GROUP BY使用了不是第一个表的列 例如：SELECT * from TableA, TableB ORDER BY TableA.price GROUP by TableB.name
3）ORDER BY中使用了DISTINCT关键字 ORDERY BY DISTINCT(price)
4）SELECT语句中指定了SQL_SMALL_RESULT关键字 SQL_SMALL_RESULT的意思就是告诉MySQL，结果会很小，请直接使用内存临时表，不需要使用索引排序 SQL_SMALL_RESULT必须和GROUP BY、DISTINCT或DISTINCTROW一起使用 一般情况下，我们没有必要使用这个选项，让MySQL服务器选择即可。

    直接使用磁盘临时表的场景

1）表包含TEXT或者BLOB列；
2）GROUP BY 或者 DISTINCT 子句中包含长度大于512字节的列；
3）使用UNION或者UNION ALL时，SELECT子句中包含大于512字节的列；

    表的设计原则

使用临时表一般都意味着性能比较低，特别是使用磁盘临时表，性能更慢，因此我们在实际应用中应该尽量避免临时表的使用。 常见的避免临时表的方法有：
1）创建索引：在ORDER BY或者GROUP BY的列上创建索引；
2）分拆很长的列：一般情况下，TEXT、BLOB，大于512字节的字符串，基本上都是为了显示信息，而不会用于查询条件， 因此表设计的时候，应该将这些列独立到另外一张表。

    SQL优化

如果表的设计已经确定，修改比较困难，那么也可以通过优化SQL语句来减少临时表的大小，以提升SQL执行效率。
常见的优化SQL语句方法如下：
1）拆分SQL语句
临时表主要是用于排序和分组，很多业务都是要求排序后再取出详细的分页数据，这种情况下可以将排序和取出详细数据拆分成不同的SQL，以降低排序或分组时临时表的大小，提升排序和分组的效率，我们的案例就是采用这种方法。
2）优化业务，去掉排序分组等操作
有时候业务其实并不需要排序或分组，仅仅是为了好看或者阅读方便而进行了排序，例如数据导出、数据查询等操作，这种情况下去掉排序和分组对业务也没有多大影响。

    如何判断使用了临时表？

使用explain查看执行计划，Extra列看到Using temporary就意味着使用了临时表。


binlog格式:statement(日志保存执行语句),row(日志保存被修改的记录),mixed
      查看:show variables like 'binlog_format'或cat /etc/my.cnf
      修改:set globle binlog_format='MIXED'
      https://blog.csdn.net/ouyang111222/article/details/50300851
  
 redo log:当数据库对数据做修改的时候，需要把数据页从磁盘读到 buffer pool 中，然后在 buffer pool 中进行修改，那么这个时候 buffer pool 中的数据页就与磁盘上的数据页内容不一致，我们称 buffer pool 的数据页为 dirty page 脏数据。
    这里也可以看出，所有的更新操作都是现在 dirty page 中进行的。
    如果这个时候发生非正常的 DB 服务重启，那么这些数据还没在内存，并没有同步到磁盘文件中（注意，同步到磁盘文件是个随机 IO），也就是会发生数据丢失。
    如果这个时候，能够在有一个文件，当 buffer pool 中的 dirty page 变更结束后，把相应修改记录记录到这个文件（注意，记录日志是顺序 IO），那么当 DB 服务发生 crash 的情况，恢复 DB 的时候，也可以根据这个文件的记录内容，重新应用到磁盘文件，数据保持一致。
    这个文件就是 redo log ，用于记录数据修改后的记录，顺序记录。
    我理解的，redo log 就是存放 dirty page 的物理空间。 
 <!-----------------------------------------------------------------   
 mysql8窗口函数:类似Oracle row_number() over(partition by order by)
          -->
          序号函数：row_number() / rank() / dense_rank()
          分布函数：percent_rank() / cume_dist()
          前后函数：lag() / lead()
          头尾函数：first_val() / last_val()
          其他函数：nth_value() / nfile()
 <!======================================================================         

